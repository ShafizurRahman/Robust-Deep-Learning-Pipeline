{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Pipeline: To generate the labels using trained classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_models_no_mask = [\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_50_SPLIT1new.hdf5',\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_50_SPLIT2new.hdf5',\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_50_SPLIT3new.hdf5',\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_50_SPLIT4new.hdf5',\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_50_SPLIT5new.hdf5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_models_mask = [\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_MJW_1.hdf5',\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_MJW_2.hdf5',\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_MJW_3.hdf5',\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_MJW_4.hdf5',\n",
    "    'data_2/macro_classifiers/DCBL_macro_TTV_MJW_5.hdf5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "models_no_mask = []\n",
    "model_mask = []\n",
    "\n",
    "for file_m in file_models_no_mask:\n",
    "    print(file_m)\n",
    "    model = load_model(file_m)\n",
    "    models_no_mask.append(model)\n",
    "\n",
    "\n",
    "\n",
    "for file_m in file_models_mask:\n",
    "    print(file_m)\n",
    "    model = load_model(file_m)\n",
    "    model_mask.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the final test dataset with no masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_IMU_files_no_mask(parent_dir, sub_dirs, startTime, endTime, file_name, window_length):\n",
    "    data = []\n",
    "    \n",
    "    data_count = 0\n",
    "    \n",
    "    for sub_dir in sub_dirs:\n",
    "        channel=[]\n",
    "        \n",
    "        for fn in glob.glob(os.path.join(parent_dir,sub_dir, file_name)):\n",
    "            file = open(fn, newline='')\n",
    "            reader = csv.reader(file)\n",
    "            first = True\n",
    "            count = 0\n",
    "            for row in reader:\n",
    "                \n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue\n",
    "                \n",
    "                timestamp=float(row[3]) #4th column is timestamp\n",
    "                if timestamp >=startTime and timestamp <=endTime and count<window_length:\n",
    "                    \n",
    "                    channel.append([float(row[0]),float(row[1]),float(row[2])])\n",
    "                    count = count + 1 \n",
    "                    data_count = data_count+1\n",
    "                    \n",
    "        data.append(channel)         \n",
    "    return data, data_count\n",
    "\n",
    "\n",
    "def parse_IMU_files_mask(parent_dir, sub_dirs, startTime, endTime, file_name, window_length):\n",
    "    \n",
    "    data = []\n",
    "    data_mask = []\n",
    "    \n",
    "    data_count = 0\n",
    "    \n",
    "    for sub_dir in sub_dirs:\n",
    "        \n",
    "        channel=[[0.0, 0.0, 0.0]]*window_length\n",
    "        \n",
    "        mask = [0.0]*window_length\n",
    "        \n",
    "        div_bucket = int(10000/window_length)\n",
    "        \n",
    "        for fn in glob.glob(os.path.join(parent_dir,sub_dir, file_name)):\n",
    "            file = open(fn, newline='')\n",
    "            reader = csv.reader(file)\n",
    "            first = True\n",
    "            count = 0\n",
    "            for row in reader:\n",
    "                \n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue\n",
    "                \n",
    "                timestamp=float(row[3]) #4th column is timestamp\n",
    "                if timestamp >=startTime and timestamp <=endTime and count<window_length:\n",
    "                    \n",
    "                    curr_bucket = timestamp - startTime #can go from 0 to 10,000\n",
    "                    \n",
    "                    curr_bucket = int(curr_bucket/div_bucket) #can go from 0 to 500\n",
    "                     \n",
    "                    if curr_bucket<window_length:\n",
    "                        channel[curr_bucket] = [float(row[0]),float(row[1]),float(row[2])]\n",
    "                        mask[curr_bucket] = 1.0\n",
    "\n",
    "                        count = count + 1 \n",
    "                        data_count = data_count+1\n",
    "                    \n",
    "                                       \n",
    "        data.append(channel) \n",
    "        data_mask.append(mask)\n",
    "    return data, data_mask, data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "#import cv2\n",
    "import io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min_count = 100 # per sample, valid points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def get_macro_label(data_dir, sub_dirs):\n",
    "\n",
    "    files = os.listdir(data_dir+'/left_hip')\n",
    "    number_of_samples = 500\n",
    "\n",
    "    labels_macro =dict()\n",
    "\n",
    "    labels_macro['sandwich'] = 0\n",
    "    labels_macro['fruitsalad'] = 1\n",
    "    labels_macro['cereal'] = 2\n",
    "\n",
    "\n",
    "    #read the labels, to verify on a sample test\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping = dict()\n",
    "\n",
    "    first = True\n",
    "    for row in label_reader:\n",
    "\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "\n",
    "        file_label_mapping[row[0]+'.csv'] = labels_macro[row[1]]\n",
    "\n",
    "\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        file_data_mask = []\n",
    "        file_data_no_mask = []\n",
    "        \n",
    "        file_label = []\n",
    "\n",
    "        st_index = 0\n",
    "        end_index = 30000\n",
    "        step = 1000 #overlapping window, step: 1000. \n",
    "        window_index = 10000 #6 second window\n",
    "\n",
    "        #print('reading file:',f)\n",
    "        f_name = f\n",
    "\n",
    "        if f_name == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        total_count = total_count+1\n",
    "\n",
    "        curr_label_file = file_label_mapping[f_name]\n",
    "\n",
    "        while st_index+step < end_index:\n",
    "\n",
    "            data, data_mask, data_count = parse_IMU_files_mask(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            data2, data_count = parse_IMU_files_no_mask(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            \n",
    "            \n",
    "            \n",
    "            st_index = st_index+step\n",
    "\n",
    "            if data_count<data_min_count:\n",
    "                continue\n",
    "\n",
    "            data_sample_mask  = np.zeros((12, number_of_samples))\n",
    "            \n",
    "            data_sample_no_mask  = np.zeros((9, number_of_samples))\n",
    "\n",
    "\n",
    "            data_label   = curr_label_file\n",
    "            \n",
    "            #print(len(data), len(data[0]), len(data_mask[0]), data_count)\n",
    "            \n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    data_sample_mask[i*4,j]=data[i][j][0]\n",
    "                    data_sample_mask[i*4+1,j]=data[i][j][1]\n",
    "                    data_sample_mask[i*4+2,j]=data[i][j][2]\n",
    "                    \n",
    "                    #mask information\n",
    "                    data_sample_mask[i*4+3,j]=data_mask[i][j]\n",
    "\n",
    "            file_data_mask.append(data_sample_mask)\n",
    "            \n",
    "            \n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    data_sample_no_mask[i*3,j]=data[i][j][0]\n",
    "                    data_sample_no_mask[i*3+1,j]=data[i][j][1]\n",
    "                    data_sample_no_mask[i*3+2,j]=data[i][j][2]\n",
    "                    \n",
    "\n",
    "            file_data_no_mask.append(data_sample_no_mask)\n",
    "            \n",
    "            \n",
    "\n",
    "        file_data_mask = np.array(file_data_mask)\n",
    "        file_data_no_mask = np.array(file_data_no_mask)\n",
    "        \n",
    "        file_label = curr_label_file\n",
    "\n",
    "        file_data_mask = file_data_mask.reshape((-1, 12,500, 1))\n",
    "        \n",
    "        file_data_no_mask = file_data_no_mask.reshape((-1, 9,500, 1))\n",
    "        \n",
    "        \n",
    "        y_pred_final = []\n",
    "        for model in models_no_mask:\n",
    "            y_pred = np.argmax(model.predict(file_data_no_mask), axis=1)\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred_final.append(y_pred[i])\n",
    "            #print(y_pred.shape)\n",
    "            #print(y_pred)\n",
    "        \n",
    "        \n",
    "        for model in model_mask:\n",
    "            y_pred = np.argmax(model.predict(file_data_mask), axis=1)\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred_final.append(y_pred[i])\n",
    "        \n",
    "        y_pred_final = np.array(y_pred_final)\n",
    "        \n",
    "        \n",
    "        #print(y_pred_final)\n",
    "        #counts = np.bincount(y_pred_final)\n",
    "        #prediction = np.argmax(counts) #max occuring value in windows\n",
    "        prediction,count_ = stats.mode(y_pred_final)\n",
    "        \n",
    "        \n",
    "        print('Final Prediction is:', prediction, 'file_label:', file_label)\n",
    "        \n",
    "        \n",
    "        #correct prediction\n",
    "        if int(prediction)==int(file_label):\n",
    "            correct_count = correct_count+1\n",
    "        \n",
    "        #break\n",
    "    \n",
    "    return total_count, correct_count        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_train='data_2/train'\n",
    "data_dir_val= 'data_2/val'\n",
    "data_dir_test= 'data_2/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dirs = ['left_hip','right_arm','right_wrist' ] #three sensors, 9 channels total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test data accuracy:\n",
    "total_count, correct_count = get_macro_label(data_dir_test, sub_dirs)\n",
    "print('total_count of test files:', total_count)\n",
    "print('correctly predicted test files:', correct_count)\n",
    "print('Percentage accuracy:', (correct_count/total_count)*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final label generation: Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def get_macro_label(data_dir, sub_dirs):\n",
    "\n",
    "    files = os.listdir(data_dir+'/left_hip')\n",
    "    number_of_samples = 500\n",
    "\n",
    "    labels_macro =dict()\n",
    "\n",
    "    labels_macro['sandwich'] = 0\n",
    "    labels_macro['fruitsalad'] = 1\n",
    "    labels_macro['cereal'] = 2\n",
    "    \n",
    "    labels_print=['sandwich', 'fruitsalad', 'cereal']\n",
    "\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        file_data_mask = []\n",
    "        file_data_no_mask = []\n",
    "        \n",
    "        file_label = []\n",
    "\n",
    "        st_index = 0\n",
    "        end_index = 30000\n",
    "        step = 1000 #overlapping window, step: 1000. \n",
    "        window_index = 10000 #6 second window\n",
    "\n",
    "        #print('reading file:',f)\n",
    "        f_name = f\n",
    "\n",
    "        if f_name == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        total_count = total_count+1\n",
    "\n",
    "        \n",
    "        while st_index+step < end_index:\n",
    "\n",
    "            data, data_mask, data_count = parse_IMU_files_mask(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            data2, data_count = parse_IMU_files_no_mask(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            \n",
    "            \n",
    "            st_index = st_index+step\n",
    "\n",
    "            if data_count<data_min_count:\n",
    "                continue\n",
    "\n",
    "            data_sample_mask  = np.zeros((12, number_of_samples))\n",
    "            \n",
    "            data_sample_no_mask  = np.zeros((9, number_of_samples))\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            #print(len(data), len(data[0]), len(data_mask[0]), data_count)\n",
    "            \n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    data_sample_mask[i*4,j]=data[i][j][0]\n",
    "                    data_sample_mask[i*4+1,j]=data[i][j][1]\n",
    "                    data_sample_mask[i*4+2,j]=data[i][j][2]\n",
    "                    \n",
    "                    #mask information\n",
    "                    data_sample_mask[i*4+3,j]=data_mask[i][j]\n",
    "\n",
    "            file_data_mask.append(data_sample_mask)\n",
    "            \n",
    "            \n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    data_sample_no_mask[i*3,j]=data[i][j][0]\n",
    "                    data_sample_no_mask[i*3+1,j]=data[i][j][1]\n",
    "                    data_sample_no_mask[i*3+2,j]=data[i][j][2]\n",
    "                    \n",
    "\n",
    "            file_data_no_mask.append(data_sample_no_mask)\n",
    "            \n",
    "            \n",
    "\n",
    "        file_data_mask = np.array(file_data_mask)\n",
    "        file_data_no_mask = np.array(file_data_no_mask)\n",
    "        \n",
    "        file_data_mask = file_data_mask.reshape((-1, 12,500, 1))\n",
    "        \n",
    "        file_data_no_mask = file_data_no_mask.reshape((-1, 9,500, 1))\n",
    "        \n",
    "        \n",
    "        y_pred_final = []\n",
    "        for model in models_no_mask:\n",
    "            y_pred = np.argmax(model.predict(file_data_no_mask), axis=1)\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred_final.append(y_pred[i])\n",
    "            #print(y_pred.shape)\n",
    "            #print(y_pred)\n",
    "        \n",
    "        \n",
    "        for model in model_mask:\n",
    "            y_pred = np.argmax(model.predict(file_data_mask), axis=1)\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred_final.append(y_pred[i])\n",
    "        \n",
    "        y_pred_final = np.array(y_pred_final)\n",
    "        \n",
    "        \n",
    "        #print(y_pred_final)\n",
    "        #counts = np.bincount(y_pred_final)\n",
    "        #prediction = np.argmax(counts) #max occuring value in windows\n",
    "        prediction,count_ = stats.mode(y_pred_final)\n",
    "        \n",
    "        f_name_output = f_name.split('.')\n",
    "        \n",
    "        #last value is kind of %confidence from all the classifiers: 33% is by default\n",
    "        \n",
    "        print(f_name_output[0],',', labels_print[int(prediction)],',', count_/file_data_no_mask.shape[0]*10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_test= 'Competition_test/competition_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dirs = ['left_hip','right_arm','right_wrist' ] #three sensors, 9 channels total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test data accuracy:\n",
    "get_macro_label(data_dir_test, sub_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Macro and Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcut = load_model('data_micro/DCBL_micro_Cut_jitter_mask.hdf5')\n",
    "modelwash = load_model('data_micro/DCBL_micro_Wash_jitter_mask.hdf5')\n",
    "modeltake = load_model('data_micro/DCBL_micro_Take_jitter_mask.hdf5')\n",
    "modelput = load_model('data_micro/DCBL_micro_Put_jitter_mask.hdf5')\n",
    "modelpeel = load_model('data_micro/DCBL_micro_Peel_jitter_mask.hdf5')\n",
    "modeladd = load_model('data_micro/DCBL_micro_ADD_jitter_mask.hdf5')\n",
    "modelmix = load_model('data_micro/DCBL_micro_Mix_jitter_mask.hdf5')\n",
    "modelpour = load_model('data_micro/DCBL_micro_Pour_jitter_mask.hdf5')\n",
    "modelopen = load_model('data_micro/DCBL_micro_Open_jitter_mask.hdf5')\n",
    "modelother = load_model('data_micro/DCBL_micro_other_jitter_mask.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcut2 = load_model('data_micro/DCBL_micro_Cut_jitter.hdf5')\n",
    "modelwash2 = load_model('data_micro/DCBL_micro_Wash_jitter.hdf5')\n",
    "modeltake2 = load_model('data_micro/DCBL_micro_Take_jitter.hdf5')\n",
    "modelput2 = load_model('data_micro/DCBL_micro_Put_jitter.hdf5')\n",
    "modelpeel2 = load_model('data_micro/DCBL_micro_Peel_jitter.hdf5')\n",
    "modeladd2 = load_model('data_micro/DCBL_micro_ADD_jitter.hdf5')\n",
    "modelmix2 = load_model('data_micro/DCBL_micro_Mix_jitter.hdf5')\n",
    "modelpour2 = load_model('data_micro/DCBL_micro_Pour_jitter.hdf5')\n",
    "modelopen2 = load_model('data_micro/DCBL_micro_Open_jitter.hdf5')\n",
    "modelother2 = load_model('data_micro/DCBL_micro_other_jitter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def get_macro_label(data_dir, sub_dirs):\n",
    "\n",
    "    files = os.listdir(data_dir+'/left_hip')\n",
    "    number_of_samples = 500\n",
    "\n",
    "    labels_macro =dict()\n",
    "\n",
    "    labels_macro['sandwich'] = 0\n",
    "    labels_macro['fruitsalad'] = 1\n",
    "    labels_macro['cereal'] = 2\n",
    "\n",
    "\n",
    "    #read the labels, to verify on a sample test\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping = dict()\n",
    "\n",
    "    first = True\n",
    "    for row in label_reader:\n",
    "\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "\n",
    "        file_label_mapping[row[0]+'.csv'] = labels_macro[row[1]]\n",
    "        \n",
    "        \n",
    "    \n",
    "    labels_micro =dict()\n",
    "    labels_micro['Cut'] = 0\n",
    "    labels_micro['Wash'] = 1\n",
    "    labels_micro['Take'] = 2\n",
    "    labels_micro['Put'] = 3\n",
    "    labels_micro['Peel'] = 4\n",
    "    labels_micro['Add'] = 5\n",
    "    labels_micro['Mix'] = 6\n",
    "    labels_micro['Pour'] = 7\n",
    "    labels_micro['Open'] = 8\n",
    "    labels_micro['other'] = 9 \n",
    "    \n",
    "    \n",
    "    #read the labels\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping_micro = dict()\n",
    "    \n",
    "    for row in label_reader:\n",
    "        label = row[2].split(',')\n",
    "        \n",
    "        label_file_micro = [0]*10\n",
    "        for lab in label:\n",
    "            if lab!='' and lab !='micro':\n",
    "                label_file_micro[labels_micro[lab]] = 1\n",
    "                \n",
    "        \n",
    "        file_label_mapping_micro[row[0]+'.csv'] = label_file_micro\n",
    "\n",
    "\n",
    "    \n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    \n",
    "    correct_count_micro = 0\n",
    "    \n",
    "    for f in files:\n",
    "\n",
    "        file_data_mask = []\n",
    "        file_data_no_mask = []\n",
    "        \n",
    "        file_label = []\n",
    "\n",
    "        st_index = 0\n",
    "        end_index = 30000\n",
    "        step = 1000 #overlapping window, step: 1000. \n",
    "        window_index = 10000 #6 second window\n",
    "\n",
    "        #print('reading file:',f)\n",
    "        f_name = f\n",
    "\n",
    "        if f_name == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        total_count = total_count+1\n",
    "\n",
    "        curr_label_file = file_label_mapping[f_name]\n",
    "        \n",
    "        curr_label_file_micro = file_label_mapping_micro[f_name]\n",
    "        \n",
    "\n",
    "        while st_index+step < end_index:\n",
    "\n",
    "            data, data_mask, data_count = parse_IMU_files_mask(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            data2, data_count = parse_IMU_files_no_mask(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            \n",
    "            \n",
    "            \n",
    "            st_index = st_index+step\n",
    "\n",
    "            if data_count<data_min_count:\n",
    "                continue\n",
    "\n",
    "            data_sample_mask  = np.zeros((12, number_of_samples))\n",
    "            \n",
    "            data_sample_no_mask  = np.zeros((9, number_of_samples))\n",
    "\n",
    "\n",
    "            data_label   = curr_label_file\n",
    "            \n",
    "            #print(len(data), len(data[0]), len(data_mask[0]), data_count)\n",
    "            \n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    data_sample_mask[i*4,j]=data[i][j][0]\n",
    "                    data_sample_mask[i*4+1,j]=data[i][j][1]\n",
    "                    data_sample_mask[i*4+2,j]=data[i][j][2]\n",
    "                    \n",
    "                    #mask information\n",
    "                    data_sample_mask[i*4+3,j]=data_mask[i][j]\n",
    "\n",
    "            file_data_mask.append(data_sample_mask)\n",
    "            \n",
    "            \n",
    "            for i in range(len(data2)):\n",
    "                for j in range(len(data2[i])):\n",
    "                    data_sample_no_mask[i*3,j]=data2[i][j][0]\n",
    "                    data_sample_no_mask[i*3+1,j]=data2[i][j][1]\n",
    "                    data_sample_no_mask[i*3+2,j]=data2[i][j][2]\n",
    "                    \n",
    "\n",
    "            file_data_no_mask.append(data_sample_no_mask)\n",
    "            \n",
    "            \n",
    "\n",
    "        file_data_mask = np.array(file_data_mask)\n",
    "        file_data_no_mask = np.array(file_data_no_mask)\n",
    "        \n",
    "        file_label = curr_label_file\n",
    "\n",
    "        file_data_mask = file_data_mask.reshape((-1, 12,500, 1))\n",
    "        \n",
    "        file_data_no_mask = file_data_no_mask.reshape((-1, 9,500, 1))\n",
    "        \n",
    "        \n",
    "        y_pred_final = []\n",
    "        for model in models_no_mask:\n",
    "            y_pred = np.argmax(model.predict(file_data_no_mask), axis=1)\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred_final.append(y_pred[i])\n",
    "            #print(y_pred.shape)\n",
    "            #print(y_pred)\n",
    "        \n",
    "        \n",
    "        for model in model_mask:\n",
    "            y_pred = np.argmax(model.predict(file_data_mask), axis=1)\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred_final.append(y_pred[i])\n",
    "        \n",
    "        y_pred_final = np.array(y_pred_final)\n",
    "        \n",
    "        \n",
    "        #print(y_pred_final)\n",
    "        #counts = np.bincount(y_pred_final)\n",
    "        #prediction = np.argmax(counts) #max occuring value in windows\n",
    "        prediction_macro,count_ = stats.mode(y_pred_final)\n",
    "         \n",
    "        \n",
    "        ##Micro prediction\n",
    "        \n",
    "        y_pred_cut = modelcut.predict(file_data_mask)\n",
    "        y_pred_wash = modelwash.predict(file_data_mask)\n",
    "        y_pred_take = modeltake.predict(file_data_mask)\n",
    "        y_pred_put = modelput.predict(file_data_mask)\n",
    "        y_pred_peel = modelpeel.predict(file_data_mask)\n",
    "        y_pred_add = modeladd.predict(file_data_mask)\n",
    "        y_pred_mix = modelmix.predict(file_data_mask)\n",
    "        \n",
    "        y_pred_pour = modelpour.predict(file_data_mask)\n",
    "        y_pred_open = modelopen.predict(file_data_mask)\n",
    "        y_pred_other = modelother.predict(file_data_mask)\n",
    "                                      \n",
    "        y_pred_cut2 = modelcut2.predict(file_data_no_mask)\n",
    "        y_pred_wash2 = modelwash2.predict(file_data_no_mask)\n",
    "        y_pred_take2 = modeltake2.predict(file_data_no_mask)\n",
    "        y_pred_put2 = modelput2.predict(file_data_no_mask)\n",
    "        y_pred_peel2 = modelpeel2.predict(file_data_no_mask)\n",
    "        y_pred_add2 = modeladd2.predict(file_data_no_mask)\n",
    "        y_pred_mix2 = modelmix2.predict(file_data_no_mask)\n",
    "        y_pred_pour2 = modelpour2.predict(file_data_no_mask)\n",
    "        y_pred_open2 = modelopen2.predict(file_data_no_mask)\n",
    "        y_pred_other2 = modelother2.predict(file_data_no_mask)\n",
    "          \n",
    "            \n",
    "        \n",
    "        y_pred = np.zeros((file_data_mask.shape[0],10))\n",
    "        \n",
    "        for j in range(0,y_pred.shape[0]):\n",
    "            if(y_pred_cut[j,0]>=y_pred_cut[j,1]):\n",
    "                y_pred[j,0] = 1\n",
    "            if(y_pred_wash[j,0]>=y_pred_wash[j,1]):\n",
    "                y_pred[j,1] = 1\n",
    "            if(y_pred_take[j,0]>=y_pred_take[j,1]):\n",
    "                y_pred[j,2] = 1\n",
    "            if(y_pred_put[j,0]>=y_pred_put[j,1]):\n",
    "                y_pred[j,3] = 1\n",
    "            if(y_pred_peel[j,0]>=y_pred_peel[j,1]):\n",
    "                y_pred[j,4] = 1\n",
    "            if(y_pred_add[j,0]>=y_pred_add[j,1]):\n",
    "                y_pred[j,5] = 1\n",
    "            if(y_pred_mix[j,0]>=y_pred_mix[j,1]):\n",
    "                y_pred[j,6] = 1\n",
    "            if(y_pred_pour[j,0]>=y_pred_pour[j,1]):\n",
    "                y_pred[j,7] = 1\n",
    "            if(y_pred_open[j,0]>=y_pred_open[j,1]):\n",
    "                y_pred[j,8] = 1\n",
    "            if(y_pred_other[j,0]>=y_pred_other[j,1]):\n",
    "                y_pred[j,9] = 1\n",
    "        \n",
    "                                        \n",
    "        y_pred2 = np.zeros((file_data_mask.shape[0],10))\n",
    "        \n",
    "        for j in range(0,y_pred2.shape[0]):\n",
    "            if(y_pred_cut2[j,0]>=y_pred_cut2[j,1]):\n",
    "                y_pred2[j,0] = 1\n",
    "            if(y_pred_wash2[j,0]>=y_pred_wash2[j,1]):\n",
    "                y_pred2[j,1] = 1\n",
    "            if(y_pred_take2[j,0]>=y_pred_take2[j,1]):\n",
    "                y_pred2[j,2] = 1\n",
    "            if(y_pred_put2[j,0]>=y_pred_put2[j,1]):\n",
    "                y_pred2[j,3] = 1\n",
    "            if(y_pred_peel2[j,0]>=y_pred_peel2[j,1]):\n",
    "                y_pred2[j,4] = 1\n",
    "            if(y_pred_add2[j,0]>=y_pred_add2[j,1]):\n",
    "                y_pred2[j,5] = 1\n",
    "            if(y_pred_mix2[j,0]>=y_pred_mix2[j,1]):\n",
    "                y_pred2[j,6] = 1\n",
    "            if(y_pred_pour2[j,0]>=y_pred_pour2[j,1]):\n",
    "                y_pred2[j,7] = 1\n",
    "            if(y_pred_open2[j,0]>=y_pred_open2[j,1]):\n",
    "                y_pred2[j,8] = 1\n",
    "            if(y_pred_other2[j,0]>=y_pred_other2[j,1]):\n",
    "                y_pred2[j,9] = 1\n",
    "        \n",
    "        #print(y_pred.shape)\n",
    "        \n",
    "        #print(y_pred)\n",
    "        #y_pred = np.where(y_pred > 0, 1, 0)\n",
    "        \n",
    "        loc_arr = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "        \n",
    "        \n",
    "        #uncomment for fusion\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            loc_arr = loc_arr + y_pred[i]\n",
    "                                        \n",
    "        for i in range(y_pred2.shape[0]):\n",
    "            loc_arr = loc_arr + y_pred2[i]\n",
    "            \n",
    "            \n",
    "#         for i in range(y_pred2.shape[0]):\n",
    "#             loc_arr = loc_arr + y_pred2[i]\n",
    "        \n",
    "        \n",
    "        loc_arr = loc_arr/(y_pred.shape[0] + y_pred2.shape[0])\n",
    "        \n",
    "        #loc_arr = loc_arr/(y_pred2.shape[0])\n",
    "        \n",
    "        max_val = loc_arr.max()\n",
    "        \n",
    "        loc_arr = np.where(loc_arr > max_val/3.0, 1, 0)\n",
    "        \n",
    "        \n",
    "        #if else logic\n",
    "        \n",
    "        if int(prediction_macro)==0:\n",
    "            #cut=0,wash=1,take=2,put=3,other=9\n",
    "            loc_arr[4]=0\n",
    "            loc_arr[5]=0\n",
    "            loc_arr[6]=0\n",
    "            loc_arr[7]=0\n",
    "            loc_arr[8]=0\n",
    "        \n",
    "        \n",
    "        if int(prediction_macro)==1:\n",
    "            #cut=0, take=2, put=3, peel=4, add=5, mix=6, other=9\n",
    "            loc_arr[1]=0\n",
    "            loc_arr[7]=0\n",
    "            loc_arr[8]=0\n",
    "        \n",
    "        \n",
    "        if int(prediction_macro)==2:\n",
    "            #cut=0, take=2, put=3, peel=4, pour=7, open=8,  other=9\n",
    "            loc_arr[1]=0\n",
    "            loc_arr[5]=0\n",
    "            loc_arr[6]=0 \n",
    "        \n",
    "        \n",
    "        file_label_micro = np.array(curr_label_file_micro)\n",
    "        \n",
    "        \n",
    "        #correct prediction\n",
    "        if np.array_equal(file_label_micro, loc_arr):\n",
    "            correct_count_micro = correct_count_micro+1\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('Final Prediction is:', prediction_macro, 'file_label:', file_label, 'label micro',file_label_micro, loc_arr)\n",
    "        \n",
    "        \n",
    "        #correct prediction\n",
    "        if int(prediction_macro)==int(file_label):\n",
    "            correct_count = correct_count+1\n",
    "        \n",
    "        #break\n",
    "    \n",
    "    return total_count, correct_count, correct_count_micro     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test data accuracy:\n",
    "#data_dir_test= 'data_2/test'\n",
    "\n",
    "data_dir_test= 'test'\n",
    "\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "total_count, correct_count, correct_count_micro = get_macro_label(data_dir_test, sub_dirs)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Percentage accuracy:', (correct_count/total_count)*100.0, (correct_count_micro/total_count)*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final label generation of the competition test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def get_macro_label(data_dir, sub_dirs):\n",
    "\n",
    "    files = os.listdir(data_dir+'/left_hip')\n",
    "    number_of_samples = 500\n",
    "\n",
    "    labels_print=['sandwich', 'fruitsalad', 'cereal']\n",
    "    \n",
    "    labels_micro_print= ['Cut','Wash','Take','Put','Peel','Add','Mix', 'Pour','Open', 'other']\n",
    "    \n",
    "    \n",
    "    all_output_to_save = []\n",
    "    \n",
    "    \n",
    "    labels_macro =dict()\n",
    "\n",
    "    labels_macro['sandwich'] = 0\n",
    "    labels_macro['fruitsalad'] = 1\n",
    "    labels_macro['cereal'] = 2\n",
    "\n",
    "\n",
    "    #read the labels, to verify on a sample test\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping = dict()\n",
    "\n",
    "    first = True\n",
    "    for row in label_reader:\n",
    "\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "\n",
    "        file_label_mapping[row[0]+'.csv'] = labels_macro[row[1]]\n",
    "        \n",
    "        \n",
    "    \n",
    "    labels_micro =dict()\n",
    "    labels_micro['Cut'] = 0\n",
    "    labels_micro['Wash'] = 1\n",
    "    labels_micro['Take'] = 2\n",
    "    labels_micro['Put'] = 3\n",
    "    labels_micro['Peel'] = 4\n",
    "    labels_micro['Add'] = 5\n",
    "    labels_micro['Mix'] = 6\n",
    "    labels_micro['Pour'] = 7\n",
    "    labels_micro['Open'] = 8\n",
    "    labels_micro['other'] = 9 \n",
    "    \n",
    "    \n",
    "    #read the labels\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping_micro = dict()\n",
    "    \n",
    "    for row in label_reader:\n",
    "        label = row[2].split(',')\n",
    "        \n",
    "        label_file_micro = [0]*10\n",
    "        for lab in label:\n",
    "            if lab!='' and lab !='micro':\n",
    "                label_file_micro[labels_micro[lab]] = 1\n",
    "                \n",
    "        \n",
    "        file_label_mapping_micro[row[0]+'.csv'] = label_file_micro\n",
    "\n",
    "\n",
    "    \n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    \n",
    "    correct_count_micro = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for f in files:\n",
    "\n",
    "        file_data_mask = []\n",
    "        file_data_no_mask = []\n",
    "        \n",
    "        file_label = []\n",
    "\n",
    "        st_index = 0\n",
    "        end_index = 30000\n",
    "        step = 1000 #overlapping window, step: 1000. \n",
    "        window_index = 10000 #6 second window\n",
    "\n",
    "        #print('reading file:',f)\n",
    "        f_name = f\n",
    "\n",
    "        if f_name == '.DS_Store':\n",
    "            continue\n",
    "            \n",
    "        \n",
    "\n",
    "        while st_index+step < end_index:\n",
    "\n",
    "            data, data_mask, data_count = parse_IMU_files_mask(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            data2, data_count = parse_IMU_files_no_mask(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            \n",
    "            \n",
    "            \n",
    "            st_index = st_index+step\n",
    "\n",
    "            if data_count<data_min_count:\n",
    "                continue\n",
    "\n",
    "            data_sample_mask  = np.zeros((12, number_of_samples))\n",
    "            \n",
    "            data_sample_no_mask  = np.zeros((9, number_of_samples))\n",
    "\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    data_sample_mask[i*4,j]=data[i][j][0]\n",
    "                    data_sample_mask[i*4+1,j]=data[i][j][1]\n",
    "                    data_sample_mask[i*4+2,j]=data[i][j][2]\n",
    "                    \n",
    "                    #mask information\n",
    "                    data_sample_mask[i*4+3,j]=data_mask[i][j]\n",
    "\n",
    "            file_data_mask.append(data_sample_mask)\n",
    "            \n",
    "            \n",
    "            for i in range(len(data2)):\n",
    "                for j in range(len(data2[i])):\n",
    "                    data_sample_no_mask[i*3,j]=data2[i][j][0]\n",
    "                    data_sample_no_mask[i*3+1,j]=data2[i][j][1]\n",
    "                    data_sample_no_mask[i*3+2,j]=data2[i][j][2]\n",
    "                    \n",
    "\n",
    "            file_data_no_mask.append(data_sample_no_mask)\n",
    "            \n",
    "            \n",
    "\n",
    "        file_data_mask = np.array(file_data_mask)\n",
    "        file_data_no_mask = np.array(file_data_no_mask)\n",
    "        \n",
    "        #file_label = curr_label_file\n",
    "\n",
    "        file_data_mask = file_data_mask.reshape((-1, 12,500, 1))\n",
    "        \n",
    "        file_data_no_mask = file_data_no_mask.reshape((-1, 9,500, 1))\n",
    "        \n",
    "        \n",
    "        y_pred_final = []\n",
    "        for model in models_no_mask:\n",
    "            y_pred = np.argmax(model.predict(file_data_no_mask), axis=1)\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred_final.append(y_pred[i])\n",
    "            #print(y_pred.shape)\n",
    "            #print(y_pred)\n",
    "        \n",
    "        \n",
    "        for model in model_mask:\n",
    "            y_pred = np.argmax(model.predict(file_data_mask), axis=1)\n",
    "            \n",
    "            for i in range(y_pred.shape[0]):\n",
    "                y_pred_final.append(y_pred[i])\n",
    "        \n",
    "        y_pred_final = np.array(y_pred_final)\n",
    "        \n",
    "        \n",
    "        #print(y_pred_final)\n",
    "        #counts = np.bincount(y_pred_final)\n",
    "        #prediction = np.argmax(counts) #max occuring value in windows\n",
    "        prediction_macro,count_ = stats.mode(y_pred_final)\n",
    "         \n",
    "        \n",
    "        ##Micro prediction\n",
    "        \n",
    "        y_pred_cut = modelcut.predict(file_data_mask)\n",
    "        y_pred_wash = modelwash.predict(file_data_mask)\n",
    "        y_pred_take = modeltake.predict(file_data_mask)\n",
    "        y_pred_put = modelput.predict(file_data_mask)\n",
    "        y_pred_peel = modelpeel.predict(file_data_mask)\n",
    "        y_pred_add = modeladd.predict(file_data_mask)\n",
    "        y_pred_mix = modelmix.predict(file_data_mask)\n",
    "        \n",
    "        y_pred_pour = modelpour.predict(file_data_mask)\n",
    "        y_pred_open = modelopen.predict(file_data_mask)\n",
    "        y_pred_other = modelother.predict(file_data_mask)\n",
    "                                      \n",
    "        y_pred_cut2 = modelcut2.predict(file_data_no_mask)\n",
    "        y_pred_wash2 = modelwash2.predict(file_data_no_mask)\n",
    "        y_pred_take2 = modeltake2.predict(file_data_no_mask)\n",
    "        y_pred_put2 = modelput2.predict(file_data_no_mask)\n",
    "        y_pred_peel2 = modelpeel2.predict(file_data_no_mask)\n",
    "        y_pred_add2 = modeladd2.predict(file_data_no_mask)\n",
    "        y_pred_mix2 = modelmix2.predict(file_data_no_mask)\n",
    "        y_pred_pour2 = modelpour2.predict(file_data_no_mask)\n",
    "        y_pred_open2 = modelopen2.predict(file_data_no_mask)\n",
    "        y_pred_other2 = modelother2.predict(file_data_no_mask)\n",
    "          \n",
    "            \n",
    "        \n",
    "        y_pred = np.zeros((file_data_mask.shape[0],10))\n",
    "        \n",
    "        for j in range(0,y_pred.shape[0]):\n",
    "            if(y_pred_cut[j,0]>=y_pred_cut[j,1]):\n",
    "                y_pred[j,0] = 1\n",
    "            if(y_pred_wash[j,0]>=y_pred_wash[j,1]):\n",
    "                y_pred[j,1] = 1\n",
    "            if(y_pred_take[j,0]>=y_pred_take[j,1]):\n",
    "                y_pred[j,2] = 1\n",
    "            if(y_pred_put[j,0]>=y_pred_put[j,1]):\n",
    "                y_pred[j,3] = 1\n",
    "            if(y_pred_peel[j,0]>=y_pred_peel[j,1]):\n",
    "                y_pred[j,4] = 1\n",
    "            if(y_pred_add[j,0]>=y_pred_add[j,1]):\n",
    "                y_pred[j,5] = 1\n",
    "            if(y_pred_mix[j,0]>=y_pred_mix[j,1]):\n",
    "                y_pred[j,6] = 1\n",
    "            if(y_pred_pour[j,0]>=y_pred_pour[j,1]):\n",
    "                y_pred[j,7] = 1\n",
    "            if(y_pred_open[j,0]>=y_pred_open[j,1]):\n",
    "                y_pred[j,8] = 1\n",
    "            if(y_pred_other[j,0]>=y_pred_other[j,1]):\n",
    "                y_pred[j,9] = 1\n",
    "        \n",
    "                                        \n",
    "        y_pred2 = np.zeros((file_data_no_mask.shape[0],10))\n",
    "        \n",
    "        for j in range(0,y_pred2.shape[0]):\n",
    "            if(y_pred_cut2[j,0]>=y_pred_cut2[j,1]):\n",
    "                y_pred2[j,0] = 1\n",
    "            if(y_pred_wash2[j,0]>=y_pred_wash2[j,1]):\n",
    "                y_pred2[j,1] = 1\n",
    "            if(y_pred_take2[j,0]>=y_pred_take2[j,1]):\n",
    "                y_pred2[j,2] = 1\n",
    "            if(y_pred_put2[j,0]>=y_pred_put2[j,1]):\n",
    "                y_pred2[j,3] = 1\n",
    "            if(y_pred_peel2[j,0]>=y_pred_peel2[j,1]):\n",
    "                y_pred2[j,4] = 1\n",
    "            if(y_pred_add2[j,0]>=y_pred_add2[j,1]):\n",
    "                y_pred2[j,5] = 1\n",
    "            if(y_pred_mix2[j,0]>=y_pred_mix2[j,1]):\n",
    "                y_pred2[j,6] = 1\n",
    "            if(y_pred_pour2[j,0]>=y_pred_pour2[j,1]):\n",
    "                y_pred2[j,7] = 1\n",
    "            if(y_pred_open2[j,0]>=y_pred_open2[j,1]):\n",
    "                y_pred2[j,8] = 1\n",
    "            if(y_pred_other2[j,0]>=y_pred_other2[j,1]):\n",
    "                y_pred2[j,9] = 1\n",
    "        \n",
    "        #print(y_pred.shape)\n",
    "        \n",
    "        #print(y_pred)\n",
    "        #y_pred = np.where(y_pred > 0, 1, 0)\n",
    "        \n",
    "        loc_arr = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "        \n",
    "        \n",
    "        #uncomment for fusion\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            loc_arr = loc_arr + y_pred[i]\n",
    "                                        \n",
    "        for i in range(y_pred2.shape[0]):\n",
    "            loc_arr = loc_arr + y_pred2[i]\n",
    "            \n",
    "            \n",
    "#         for i in range(y_pred.shape[0]):\n",
    "#             loc_arr = loc_arr + y_pred[i]\n",
    "        \n",
    "        \n",
    "        loc_arr = loc_arr/(y_pred.shape[0] + y_pred2.shape[0])\n",
    "        \n",
    "        #loc_arr = loc_arr/(y_pred.shape[0])\n",
    "        \n",
    "        max_val = loc_arr.max()\n",
    "        \n",
    "        loc_arr = np.where(loc_arr > max_val/3.0, 1, 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        f_name_output = f_name.split('.')\n",
    "        \n",
    "        \n",
    "        if int(prediction_macro)==0:\n",
    "            #cut=0,wash=1,take=2,put=3,other=9\n",
    "            loc_arr[4]=0\n",
    "            loc_arr[5]=0\n",
    "            loc_arr[6]=0\n",
    "            loc_arr[7]=0\n",
    "            loc_arr[8]=0\n",
    "        \n",
    "        \n",
    "        if int(prediction_macro)==1:\n",
    "            #cut=0, take=2, put=3, peel=4, add=5, mix=6, other=9\n",
    "            loc_arr[1]=0\n",
    "            loc_arr[7]=0\n",
    "            loc_arr[8]=0\n",
    "        \n",
    "        \n",
    "        if int(prediction_macro)==2:\n",
    "            #cut=0, take=2, put=3, peel=4, pour=7, open=8,  other=9\n",
    "            loc_arr[1]=0\n",
    "            loc_arr[5]=0\n",
    "            loc_arr[6]=0 \n",
    "        \n",
    "        output_micro = ''\n",
    "        \n",
    "        for i in range(loc_arr.shape[0]):\n",
    "            if loc_arr[i]==1:\n",
    "                output_micro = output_micro+','+labels_micro_print[i] \n",
    "        \n",
    "        all_output_to_save.append([f_name_output[0],labels_print[int(prediction_macro)], output_micro])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        curr_label_file = file_label_mapping[f_name]\n",
    "        \n",
    "        curr_label_file_micro = file_label_mapping_micro[f_name]\n",
    "        \n",
    "        #correct prediction\n",
    "        if int(prediction_macro)==int(curr_label_file):\n",
    "            correct_count = correct_count+1\n",
    "        \n",
    "        if np.array_equal(curr_label_file_micro, loc_arr):\n",
    "            correct_count_micro = correct_count_micro+1\n",
    "        \n",
    "        print(correct_count, correct_count_micro)\n",
    "        \n",
    "    #return all_output_to_save\n",
    "    return total_count, correct_count, correct_count_micro     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir_test= 'Competition_test/competition_test'\n",
    "\n",
    "data_dir_test= 'data_2/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dirs = ['left_hip','right_arm','right_wrist' ] #three sensors, 9 channels total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_count, correct_count, correct_count_micro = get_macro_label(data_dir_test, sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage accuracy:', (correct_count/50)*100.0, (correct_count_micro/50)*100.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
