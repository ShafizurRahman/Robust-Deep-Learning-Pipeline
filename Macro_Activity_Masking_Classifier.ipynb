{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jPihmLbUvoa"
   },
   "source": [
    "# Train macro classifiers with masking for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window jitter and time shift data augmentation is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWzF5-ugUvoc"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shutil\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options to set if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess)  # set this TensorFlow session as the default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDej6DfZUvol"
   },
   "outputs": [],
   "source": [
    "data_dir_train='data_2/train'\n",
    "data_dir_val= 'data_2/val'\n",
    "data_dir_test= 'data_2/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q87cb-fJUvoo"
   },
   "outputs": [],
   "source": [
    "sub_dirs = ['left_hip','right_arm','right_wrist' ] #three sensors, 9 channels total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the buckets information\n",
    "\n",
    "def parse_IMU_files(parent_dir, sub_dirs, startTime, endTime, file_name, window_length):\n",
    "    \n",
    "    data = []\n",
    "    data_mask = []\n",
    "    \n",
    "    data_count = 0\n",
    "    \n",
    "    for sub_dir in sub_dirs:\n",
    "        \n",
    "        channel=[[0.0, 0.0, 0.0]]*window_length\n",
    "        \n",
    "        mask = [0.0]*window_length\n",
    "        \n",
    "        div_bucket = int(10000/window_length)\n",
    "        \n",
    "        for fn in glob.glob(os.path.join(parent_dir,sub_dir, file_name)):\n",
    "            file = open(fn, newline='')\n",
    "            reader = csv.reader(file)\n",
    "            first = True\n",
    "            count = 0\n",
    "            for row in reader:\n",
    "                \n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue\n",
    "                \n",
    "                timestamp=float(row[3]) #4th column is timestamp\n",
    "                if timestamp >=startTime and timestamp <=endTime and count<window_length:\n",
    "                    \n",
    "                    curr_bucket = timestamp - startTime #can go from 0 to 10,000\n",
    "                    \n",
    "                    curr_bucket = int(curr_bucket/div_bucket) #can go from 0 to 500\n",
    "                    \n",
    "                    \n",
    "                    if curr_bucket<window_length:\n",
    "                        channel[curr_bucket] = [float(row[0]),float(row[1]),float(row[2])]\n",
    "                        mask[curr_bucket] = 1.0\n",
    "\n",
    "                        count = count + 1 \n",
    "                        data_count = data_count+1\n",
    "                    \n",
    "                    \n",
    "        data.append(channel) \n",
    "        data_mask.append(mask)\n",
    "    return data, data_mask, data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min_count = 100 # per sample, valid points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking info added\n",
    "\n",
    "def get_train_data(data_dir, sub_dirs):\n",
    "    files = os.listdir(data_dir+'/left_hip')\n",
    "    number_of_samples = 500\n",
    "    \n",
    "    labels_macro =dict()\n",
    "    \n",
    "    labels_macro['sandwich'] = 0\n",
    "    labels_macro['fruitsalad'] = 1\n",
    "    labels_macro['cereal'] = 2\n",
    "    \n",
    "    \n",
    "    #read the labels\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping = dict()\n",
    "    \n",
    "    first = True\n",
    "    for row in label_reader:\n",
    "        \n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        file_label_mapping[row[0]+'.csv'] = labels_macro[row[1]]\n",
    "        \n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for f in files:\n",
    "        \n",
    "        st_index = 0\n",
    "        end_index = 30000\n",
    "        step = 1000 #overlapping window, step: 1000. \n",
    "        window_index = 10000 #10 second window\n",
    "        \n",
    "        print('reading file:',f)\n",
    "        f_name = f\n",
    "        \n",
    "        if f_name == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        curr_label_file = file_label_mapping[f_name]\n",
    "        \n",
    "        while st_index+step < end_index:\n",
    "        \n",
    "            data, data_mask, data_count = parse_IMU_files(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            \n",
    "            st_index = st_index+step\n",
    "            \n",
    "            if data_count<data_min_count:\n",
    "                continue\n",
    "            \n",
    "            train_data_sample  = np.zeros((12, number_of_samples))\n",
    "            train_data_label   = curr_label_file\n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    train_data_sample[i*4,j]=data[i][j][0]\n",
    "                    train_data_sample[i*4+1,j]=data[i][j][1]\n",
    "                    train_data_sample[i*4+2,j]=data[i][j][2]\n",
    "                    \n",
    "                    #mask information\n",
    "                    train_data_sample[i*4+3,j]=data_mask[i][j]\n",
    "            \n",
    "            all_data.append(train_data_sample)\n",
    "            all_labels.append(train_data_label)\n",
    "        \n",
    "        #break\n",
    "            \n",
    "    return all_data, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEYY86nqUvoy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#receive windowed training and validation data\n",
    "train_x, train_y = get_train_data(data_dir_train,sub_dirs)\n",
    "val_x, val_y = get_train_data(data_dir_val,sub_dirs)\n",
    "test_x, test_y = get_train_data(data_dir_test,sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the buckets information\n",
    "\n",
    "import random\n",
    "\n",
    "def parse_IMU_files_2(parent_dir, sub_dirs, startTime, endTime, file_name, window_length):\n",
    "    \n",
    "    data = []\n",
    "    data_mask = []\n",
    "    \n",
    "    data_count = 0\n",
    "    \n",
    "    for sub_dir in sub_dirs:\n",
    "        \n",
    "        channel=[[0.0, 0.0, 0.0]]*window_length\n",
    "        \n",
    "        mask = [0.0]*window_length\n",
    "        \n",
    "        div_bucket = int(10000/window_length)\n",
    "        \n",
    "        for fn in glob.glob(os.path.join(parent_dir,sub_dir, file_name)):\n",
    "            file = open(fn, newline='')\n",
    "            reader = csv.reader(file)\n",
    "            first = True\n",
    "            count = 0\n",
    "            for row in reader:\n",
    "                \n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue\n",
    "                \n",
    "                timestamp=float(row[3]) #4th column is timestamp\n",
    "                \n",
    "                window_jitter1 = random.randint(-150,150)\n",
    "                \n",
    "                window_jitter2 = random.randint(-150,150)\n",
    "                \n",
    "                \n",
    "                if timestamp >=(startTime+window_jitter1) and timestamp <=(endTime+window_jitter2) and count<window_length:\n",
    "                    \n",
    "                    curr_bucket = timestamp - startTime #can go from 0 to 10,000\n",
    "                    \n",
    "                    curr_bucket = int(curr_bucket/div_bucket) #can go from 0 to 500\n",
    "                    \n",
    "                    if curr_bucket<window_length:\n",
    "                        channel[curr_bucket] = [float(row[0]),float(row[1]),float(row[2])]\n",
    "                        mask[curr_bucket] = 1.0\n",
    "\n",
    "                        count = count + 1 \n",
    "                        data_count = data_count+1                   \n",
    "                    \n",
    "        data.append(channel) \n",
    "        data_mask.append(mask)\n",
    "    return data, data_mask, data_count\n",
    "\n",
    "\n",
    "\n",
    "def parse_IMU_files_3(parent_dir, sub_dirs, startTime, endTime, file_name, window_length):\n",
    "    \n",
    "    data = []\n",
    "    data_mask = []\n",
    "    \n",
    "    data_count = 0\n",
    "    \n",
    "    for sub_dir in sub_dirs:\n",
    "        \n",
    "        channel=[[0.0, 0.0, 0.0]]*window_length\n",
    "        \n",
    "        mask = [0.0]*window_length\n",
    "        \n",
    "        div_bucket = int(10000/window_length)\n",
    "        \n",
    "        window_jitter1 = random.randint(-1500,1500)\n",
    "        window_jitter2 = random.randint(-1500,1500)\n",
    "                \n",
    "        \n",
    "        for fn in glob.glob(os.path.join(parent_dir,sub_dir, file_name)):\n",
    "            file = open(fn, newline='')\n",
    "            reader = csv.reader(file)\n",
    "            first = True\n",
    "            count = 0\n",
    "            for row in reader:\n",
    "                \n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue\n",
    "                \n",
    "                timestamp=float(row[3]) #4th column is timestamp\n",
    "                \n",
    "                \n",
    "                if timestamp >=(startTime+window_jitter1) and timestamp <=(endTime+window_jitter2) and count<window_length:\n",
    "                    \n",
    "                    curr_bucket = timestamp - startTime #can go from 0 to 10,000\n",
    "                    \n",
    "                    curr_bucket = int(curr_bucket/div_bucket) #can go from 0 to 500\n",
    "                    \n",
    "                    if curr_bucket<window_length:\n",
    "                        channel[curr_bucket] = [float(row[0]),float(row[1]),float(row[2])]\n",
    "                        mask[curr_bucket] = 1.0\n",
    "\n",
    "                        count = count + 1 \n",
    "                        data_count = data_count+1                   \n",
    "                    \n",
    "        data.append(channel) \n",
    "        data_mask.append(mask)\n",
    "    return data, data_mask, data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking info added\n",
    "\n",
    "def get_train_data_2(data_dir, sub_dirs):\n",
    "    files = os.listdir(data_dir+'/left_hip')\n",
    "    number_of_samples = 500\n",
    "    \n",
    "    labels_macro =dict()\n",
    "    \n",
    "    labels_macro['sandwich'] = 0\n",
    "    labels_macro['fruitsalad'] = 1\n",
    "    labels_macro['cereal'] = 2\n",
    "    \n",
    "    \n",
    "    #read the labels\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping = dict()\n",
    "    \n",
    "    first = True\n",
    "    for row in label_reader:\n",
    "        \n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        file_label_mapping[row[0]+'.csv'] = labels_macro[row[1]]\n",
    "        \n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for f in files:\n",
    "        \n",
    "        st_index = 0\n",
    "        end_index = 30000\n",
    "        step = 1000 #overlapping window, step: 1000. \n",
    "        window_index = 10000 #10 second window\n",
    "        \n",
    "        print('reading file:',f)\n",
    "        f_name = f\n",
    "        \n",
    "        if f_name == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        curr_label_file = file_label_mapping[f_name]\n",
    "        \n",
    "        while st_index+step < end_index:\n",
    "        \n",
    "            data, data_mask, data_count = parse_IMU_files_2(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)    \n",
    "            st_index = st_index+step\n",
    "            \n",
    "            if data_count<data_min_count:\n",
    "                continue\n",
    "            \n",
    "            train_data_sample  = np.zeros((12, number_of_samples))\n",
    "            train_data_label   = curr_label_file\n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    train_data_sample[i*4,j]=data[i][j][0]\n",
    "                    train_data_sample[i*4+1,j]=data[i][j][1]\n",
    "                    train_data_sample[i*4+2,j]=data[i][j][2]\n",
    "                    \n",
    "                    #mask information\n",
    "                    train_data_sample[i*4+3,j]=data_mask[i][j]\n",
    "            \n",
    "            all_data.append(train_data_sample)\n",
    "            all_labels.append(train_data_label)\n",
    "        \n",
    "        #break\n",
    "            \n",
    "    return all_data, all_labels\n",
    "\n",
    "\n",
    "# Masking info added\n",
    "\n",
    "def get_train_data_3(data_dir, sub_dirs):\n",
    "    files = os.listdir(data_dir+'/left_hip')\n",
    "    number_of_samples = 500\n",
    "    \n",
    "    labels_macro =dict()\n",
    "    \n",
    "    labels_macro['sandwich'] = 0\n",
    "    labels_macro['fruitsalad'] = 1\n",
    "    labels_macro['cereal'] = 2\n",
    "    \n",
    "    \n",
    "    #read the labels\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping = dict()\n",
    "    \n",
    "    first = True\n",
    "    for row in label_reader:\n",
    "        \n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        \n",
    "        file_label_mapping[row[0]+'.csv'] = labels_macro[row[1]]\n",
    "        \n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for f in files:\n",
    "        \n",
    "        st_index = 0\n",
    "        end_index = 30000\n",
    "        step = 1000 #overlapping window, step: 1000. \n",
    "        window_index = 10000 #10 second window\n",
    "        \n",
    "        print('reading file:',f)\n",
    "        f_name = f\n",
    "        \n",
    "        if f_name == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        curr_label_file = file_label_mapping[f_name]\n",
    "        \n",
    "        while st_index+step < end_index:\n",
    "        \n",
    "            data, data_mask, data_count = parse_IMU_files_3(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)    \n",
    "            st_index = st_index+step\n",
    "            \n",
    "            if data_count<data_min_count:\n",
    "                continue\n",
    "            \n",
    "            train_data_sample  = np.zeros((12, number_of_samples))\n",
    "            train_data_label   = curr_label_file\n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    train_data_sample[i*4,j]=data[i][j][0]\n",
    "                    train_data_sample[i*4+1,j]=data[i][j][1]\n",
    "                    train_data_sample[i*4+2,j]=data[i][j][2]\n",
    "                    \n",
    "                    #mask information\n",
    "                    train_data_sample[i*4+3,j]=data_mask[i][j]\n",
    "            \n",
    "            all_data.append(train_data_sample)\n",
    "            all_labels.append(train_data_label)\n",
    "        \n",
    "        #break\n",
    "            \n",
    "    return all_data, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Window Jitters, Time Shifts and Masking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x2, train_y2 = get_train_data_2(data_dir_train,sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x3, train_y3 = get_train_data_3(data_dir_train,sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4863, 12, 500)\n",
      "(4863,)\n",
      "(4858, 12, 500)\n",
      "(4858,)\n"
     ]
    }
   ],
   "source": [
    "train_samples_2 = np.array(train_x2) \n",
    "train_labels2_2 = np.array(train_y2)\n",
    "print(train_samples_2.shape)\n",
    "print(train_labels2_2.shape)\n",
    "\n",
    "train_samples_3 = np.array(train_x3) \n",
    "train_labels2_3 = np.array(train_y3)\n",
    "print(train_samples_3.shape)\n",
    "print(train_labels2_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2w_y9dmUvo1"
   },
   "outputs": [],
   "source": [
    "train_samples = np.array(train_x) \n",
    "train_labels2 = np.array(train_y)\n",
    "val_samples = np.array(val_x) \n",
    "val_labels2 = np.array(val_y)\n",
    "test_samples = np.array(test_x) \n",
    "test_labels2 = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4864, 12, 500)\n",
      "(4864,)\n",
      "(1348, 12, 500)\n",
      "(1348,)\n",
      "(1356, 12, 500)\n",
      "(1356,)\n"
     ]
    }
   ],
   "source": [
    "print(train_samples.shape)\n",
    "print(train_labels2.shape)\n",
    "print(val_samples.shape)\n",
    "print(val_labels2.shape)\n",
    "print(test_samples.shape)\n",
    "print(test_labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = np.vstack((train_samples,train_samples_2, train_samples_3))\n",
    "train_labels2 = np.hstack((train_labels2, train_labels2_2, train_labels2_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNUKXbk9Uvo3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14585, 12, 500)\n",
      "(14585,)\n",
      "(1348, 12, 500)\n",
      "(1348,)\n",
      "(1356, 12, 500)\n",
      "(1356,)\n"
     ]
    }
   ],
   "source": [
    "print(train_samples.shape)\n",
    "print(train_labels2.shape)\n",
    "print(val_samples.shape)\n",
    "print(val_labels2.shape)\n",
    "print(test_samples.shape)\n",
    "print(test_labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1OiMsBOUvo6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1356, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to one hot encoding\n",
    "from keras.utils  import to_categorical\n",
    "train_labels = to_categorical(train_labels2)\n",
    "train_labels.shape\n",
    "val_labels = to_categorical(val_labels2)\n",
    "val_labels.shape\n",
    "test_labels = to_categorical(test_labels2)\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_d-H-X42Uvo8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14585, 12, 500)\n",
      "(14585, 3)\n",
      "(1348, 12, 500)\n",
      "(1348, 3)\n",
      "(1356, 12, 500)\n",
      "(1356,)\n"
     ]
    }
   ],
   "source": [
    "print(train_samples.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_samples.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_samples.shape)\n",
    "print(test_labels2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wqxij4vFUvo_"
   },
   "outputs": [],
   "source": [
    "#For CNN and BidirLSTM:\n",
    "number_of_samples =500\n",
    "num_of_channels = 12\n",
    "\n",
    "train_samples = train_samples.reshape((-1, num_of_channels,number_of_samples, 1))\n",
    "val_samples = val_samples.reshape((-1, num_of_channels,number_of_samples, 1))\n",
    "test_samples = test_samples.reshape((-1, num_of_channels,number_of_samples, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rf0eewtJUvpB"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyNXsGAAUvpC"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Permute, Reshape\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKNc7WZQUvpE"
   },
   "outputs": [],
   "source": [
    "def _data_reshaping(X_tr, X_va, X_ts, network_type):\n",
    "    _, win_len, dim = X_tr.shape\n",
    "    print(network_type)\n",
    "    if network_type=='CNN' or network_type=='ConvLSTM':\n",
    "\n",
    "        X_tr = np.swapaxes(X_tr,1,2)\n",
    "        X_va = np.swapaxes(X_va,1,2)\n",
    "        X_ts = np.swapaxes(X_ts,1,2)\n",
    "\n",
    "        X_tr = np.reshape(X_tr, (-1, dim, win_len, 1))\n",
    "        X_va = np.reshape(X_va, (-1, dim, win_len, 1))\n",
    "        X_ts = np.reshape(X_ts, (-1, dim, win_len, 1))\n",
    "    \n",
    "    return X_tr, X_va, X_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HcMCdtFUUvpF"
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def model_variant(model, num_feat_map, dim, network_type,p):\n",
    "    print(network_type)\n",
    "    if network_type == 'ConvLSTM':\n",
    "        model.add(Permute((2, 1, 3))) \n",
    "        model.add(Reshape((-1,num_feat_map*dim)))\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=False, stateful=False)))\n",
    "    if network_type == 'CNN':\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(BatchNormalization()) \n",
    "        model.add(Dropout(p))\n",
    "\n",
    "        \n",
    "def model_conv(model, num_feat_map,p,b):\n",
    "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10),    \n",
    "                 activation='relu',\n",
    "                 input_shape=(dim, win_len, 1),\n",
    "                 padding='same'))\n",
    "    \n",
    "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same'))\n",
    "    \n",
    "    if (b==1):\n",
    "        model.add(BatchNormalization()) \n",
    "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same'))\n",
    "    \n",
    "    if (b==1):\n",
    "        model.add(BatchNormalization()) \n",
    "    model.add(MaxPooling2D(pool_size=(1, 3)))\n",
    "    \n",
    "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same')) \n",
    "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same'))\n",
    "    if (b==1):\n",
    "        model.add(BatchNormalization()) \n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(p))\n",
    "    \n",
    "    model.add(Conv2D(num_feat_map, kernel_size=(1, 10), activation='relu',padding='same'))  \n",
    "    if (b==1):\n",
    "        model.add(BatchNormalization()) \n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    \n",
    "    model.add(Dropout(p))\n",
    "    \n",
    "def model_LSTM(model,p):\n",
    "    model.add(LSTM(num_hidden_lstm, \n",
    "               input_shape=(win_len,dim), \n",
    "               return_sequences=True))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(LSTM(num_hidden_lstm, return_sequences=False))\n",
    "    model.add(Dropout(p))\n",
    "    \n",
    "def model_output(model):\n",
    "    model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wf8LuDxlUvpH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_feat_map = 128\n",
    "num_hidden_lstm = 128\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "network_type = 'ConvLSTM'\n",
    "\n",
    "_, dim, win_len,_ = train_samples.shape\n",
    "\n",
    "print(win_len)\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fAQRf1DNUvpK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the model ... \n",
      "WARNING:tensorflow:From /home/sandeep/anaconda3/envs/sandeep-env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/sandeep/anaconda3/envs/sandeep-env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "ConvLSTM\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 12, 500, 128)      1408      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 500, 128)      163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 500, 128)      512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 500, 128)      163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 500, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 166, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 166, 128)      163968    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 166, 128)      163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 166, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 83, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 83, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 83, 128)       163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 83, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 41, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 41, 1536)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               1704960   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,529,027\n",
      "Trainable params: 2,528,003\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p=0.5 #Dropout\n",
    "b = 1 #BatchNorm\n",
    "print('building the model ... ')\n",
    "model = Sequential()\n",
    "\n",
    "if network_type=='CNN' or network_type=='ConvLSTM':\n",
    "    model_conv(model, num_feat_map,p,b)\n",
    "    model_variant(model, num_feat_map, dim, network_type,p)\n",
    "if network_type=='LSTM':\n",
    "    model_LSTM(model,p)\n",
    "       \n",
    "model_output(model)    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrNCEAD8UvpL"
   },
   "outputs": [],
   "source": [
    "X_train = train_samples\n",
    "y_train = train_labels\n",
    "X_val = val_samples\n",
    "y_val = val_labels\n",
    "X_test = test_samples\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNsDOBNrUvpN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14585, 12, 500, 1) (1348, 12, 500, 1) (1356, 12, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Checkpoint path to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint /home/sandeep/data/DCBL_macro_TTV_11.hdf5\n",
    "filepath=\"macro_with_masking.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpsJRPEfUvpP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs =40\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks_list = [checkpoint] \n",
    "H = model.fit(train_samples, train_labels,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "            validation_data=(X_val, y_val),\n",
    "             callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ASUmtFSUvpQ"
   },
   "outputs": [],
   "source": [
    "history = H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6yi5aaJUvpS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum validation accuracy:  0.921364963054657\n",
      "Training accuracy of best model:  0.9977374\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "print(np.argmax(np.array(history.history['val_accuracy'])))\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "print('Maximum validation accuracy: ',np.max(np.array(history.history['val_accuracy'])))\n",
    "print('Training accuracy of best model: ',np.array(history.history['accuracy'])[np.argmax(np.array(history.history['val_accuracy']))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test samples accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[538  37  57]\n",
      " [ 45 309  23]\n",
      " [ 72  51 224]]\n",
      "the mean-f1 score: 0.78\n",
      "accuracy is: 0.79\n"
     ]
    }
   ],
   "source": [
    "model = load_model(filepath)\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "class_wise_f1 = np.round(f1_score(y_true, y_pred, average=None)*100)*0.01\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print('the mean-f1 score: {:.2f}'.format(np.mean(class_wise_f1)))\n",
    "print('accuracy is: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5673    0    0]\n",
      " [   9 5095    5]\n",
      " [   0    0 3803]]\n",
      "the mean-f1 score: 1.00\n",
      "accuracy is: 1.00\n"
     ]
    }
   ],
   "source": [
    "model = load_model(filepath)\n",
    "y_pred = np.argmax(model.predict(train_samples), axis=1)\n",
    "y_true = np.argmax(train_labels, axis=1)\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "class_wise_f1 = np.round(f1_score(y_true, y_pred, average=None)*100)*0.01\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print('the mean-f1 score: {:.2f}'.format(np.mean(class_wise_f1)))\n",
    "print('accuracy is: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[492  10  14]\n",
      " [ 26 494  24]\n",
      " [ 25   7 256]]\n",
      "the mean-f1 score: 0.92\n",
      "accuracy is: 0.92\n"
     ]
    }
   ],
   "source": [
    "model = load_model(filepath)\n",
    "y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "class_wise_f1 = np.round(f1_score(y_true, y_pred, average=None)*100)*0.01\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print('the mean-f1 score: {:.2f}'.format(np.mean(class_wise_f1)))\n",
    "print('accuracy is: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File by file the Macro comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data windows per file and see their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_prediction_accuracy(data_dir, sub_dirs):\n",
    "\n",
    "    files = os.listdir(data_dir+'/left_hip')\n",
    "    number_of_samples = 500\n",
    "\n",
    "    labels_macro =dict()\n",
    "\n",
    "    labels_macro['sandwich'] = 0\n",
    "    labels_macro['fruitsalad'] = 1\n",
    "    labels_macro['cereal'] = 2\n",
    "\n",
    "\n",
    "    #read the labels\n",
    "    labels_loc = 'data/LabelTable.csv'\n",
    "    file_label = open(labels_loc, newline='')\n",
    "    label_reader = csv.reader(file_label)\n",
    "    file_label_mapping = dict()\n",
    "\n",
    "    first = True\n",
    "    for row in label_reader:\n",
    "\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "\n",
    "        file_label_mapping[row[0]+'.csv'] = labels_macro[row[1]]\n",
    "\n",
    "\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        file_data = []\n",
    "        file_label = []\n",
    "\n",
    "        st_index = 0\n",
    "        end_index = 30000\n",
    "        step = 1000 #overlapping window, step: 1000. \n",
    "        window_index = 10000 #6 second window\n",
    "\n",
    "        #print('reading file:',f)\n",
    "        f_name = f\n",
    "\n",
    "        if f_name == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        total_count = total_count+1\n",
    "\n",
    "        curr_label_file = file_label_mapping[f_name]\n",
    "\n",
    "        while st_index+step < end_index:\n",
    "\n",
    "            data, data_mask, data_count = parse_IMU_files(data_dir, sub_dirs, st_index, st_index+window_index,  f, number_of_samples)\n",
    "            st_index = st_index+step\n",
    "\n",
    "            if data_count<data_min_count:\n",
    "                continue\n",
    "\n",
    "            train_data_sample  = np.zeros((12, number_of_samples))\n",
    "            train_data_label   = curr_label_file\n",
    "            \n",
    "            #print(len(data), len(data[0]), len(data_mask[0]), data_count)\n",
    "            \n",
    "            for i in range(len(data)):\n",
    "                for j in range(len(data[i])):\n",
    "                    train_data_sample[i*4,j]=data[i][j][0]\n",
    "                    train_data_sample[i*4+1,j]=data[i][j][1]\n",
    "                    train_data_sample[i*4+2,j]=data[i][j][2]\n",
    "                    \n",
    "                    #mask information\n",
    "                    train_data_sample[i*4+3,j]=data_mask[i][j]\n",
    "\n",
    "            file_data.append(train_data_sample)\n",
    "            #file_label.append(train_data_label)\n",
    "\n",
    "        file_data = np.array(file_data)\n",
    "        file_label = curr_label_file\n",
    "\n",
    "        file_data = file_data.reshape((-1, 12,500, 1))\n",
    "\n",
    "        y_pred = np.argmax(model.predict(file_data), axis=1) \n",
    "        counts = np.bincount(y_pred)\n",
    "        prediction = np.argmax(counts) #max occuring value in windows\n",
    "        \n",
    "        #correct prediction\n",
    "        if int(prediction)==int(file_label):\n",
    "            correct_count = correct_count+1\n",
    "        \n",
    "    \n",
    "    return total_count, correct_count        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count of test files: 50\n",
      "correctly predicted test files: 43\n",
      "Percentage accuracy: 86.0\n"
     ]
    }
   ],
   "source": [
    "# Test data accuracy:\n",
    "total_count, correct_count = get_prediction_accuracy(data_dir_test, sub_dirs)\n",
    "print('total_count of test files:', total_count)\n",
    "print('correctly predicted test files:', correct_count)\n",
    "print('Percentage accuracy:', (correct_count/total_count)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count of train files: 175\n",
      "correctly predicted train files: 175\n",
      "Percentage accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Train accuracy\n",
    "total_count, correct_count = get_prediction_accuracy(data_dir_train, sub_dirs)\n",
    "print('total_count of train files:', total_count)\n",
    "print('correctly predicted train files:', correct_count)\n",
    "print('Percentage accuracy:', (correct_count/total_count)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count of val files: 48\n",
      "correctly predicted val files: 47\n",
      "Percentage accuracy: 97.91666666666666\n"
     ]
    }
   ],
   "source": [
    "#val accuracy\n",
    "total_count, correct_count = get_prediction_accuracy(data_dir_val, sub_dirs)\n",
    "print('total_count of val files:', total_count)\n",
    "print('correctly predicted val files:', correct_count)\n",
    "print('Percentage accuracy:', (correct_count/total_count)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Macro-Activity",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
